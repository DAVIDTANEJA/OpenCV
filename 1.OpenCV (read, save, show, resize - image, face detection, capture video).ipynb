{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Python stores the image as a Numpy array / matrix of numbers. \n",
    "colored image in - 3d matrix , if its grayscale image - 2D matrix.                                                         \n",
    "color image has 3 channels - in (Red, Green, Blue) format.  And grayscale image has 1 channel - black & white."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 53  54  52]\n",
      "  [ 53  54  52]\n",
      "  [ 53  54  52]\n",
      "  ...\n",
      "  [ 22  22  22]\n",
      "  [ 23  24  22]\n",
      "  [ 23  24  22]]\n",
      "\n",
      " [[ 54  55  53]\n",
      "  [ 54  55  53]\n",
      "  [ 53  54  52]\n",
      "  ...\n",
      "  [ 22  22  22]\n",
      "  [ 23  24  22]\n",
      "  [ 23  24  22]]\n",
      "\n",
      " [[ 55  56  54]\n",
      "  [ 54  55  53]\n",
      "  [ 54  55  53]\n",
      "  ...\n",
      "  [ 22  22  22]\n",
      "  [ 23  24  22]\n",
      "  [ 23  24  22]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 55  81 117]\n",
      "  [ 56  82 118]\n",
      "  [ 56  82 118]\n",
      "  ...\n",
      "  [  0   0   0]\n",
      "  [  0   0   0]\n",
      "  [  0   0   0]]\n",
      "\n",
      " [[ 57  83 120]\n",
      "  [ 57  83 120]\n",
      "  [ 57  83 119]\n",
      "  ...\n",
      "  [  0   0   0]\n",
      "  [  0   0   0]\n",
      "  [  0   0   0]]\n",
      "\n",
      " [[ 57  83 120]\n",
      "  [ 58  84 121]\n",
      "  [ 58  84 120]\n",
      "  ...\n",
      "  [  0   0   0]\n",
      "  [  0   0   0]\n",
      "  [  0   0   0]]]\n"
     ]
    }
   ],
   "source": [
    "img = cv2.imread(\"opencv.jpg\", 1)  \n",
    "\n",
    "# 1 : tells to keep in - colored image , its colored image it will convert into 3D matrix.\n",
    "print(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[53 53 53 ... 22 23 23]\n",
      " [54 54 53 ... 22 23 23]\n",
      " [55 54 54 ... 22 23 23]\n",
      " ...\n",
      " [89 90 90 ...  0  0  0]\n",
      " [91 91 91 ...  0  0  0]\n",
      " [91 92 92 ...  0  0  0]]\n",
      "\n",
      " shape :  (1600, 1074)\n"
     ]
    }
   ],
   "source": [
    "# 0 : gives grayscale image convert into 2D matrix\n",
    "img = cv2.imread(\"opencv.jpg\", 0)  \n",
    "print(img)\n",
    "print('\\n shape : ', img.shape)   # (height, width) of image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save image in OpenCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imwrite('grayscale.jpg', img)    # save in any format jpg, png ('file name', image object)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Show the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"opencv.jpg\", 1)  \n",
    "\n",
    "# imshow() : show image, 'legend' -image name given, img -var. stores image given above \n",
    "cv2.imshow(\"Legend\", img)  \n",
    "\n",
    "cv2.waitKey(0)           # waitKey(0) : shows image for 0 miliseconds when user presses any key\n",
    "# cv2.waitkey(2000)      # if give some miliseconds like : 2000 it will go away after it automatically \n",
    "\n",
    "cv2.destroyAllWindows()    # when user presses any key it destroy all windows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resize the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"opencv.jpg\", 1)  \n",
    "\n",
    "resized_img = cv2.resize(img, (600, 600))   # resize image - img, into (600,600) shape\n",
    "\n",
    "cv2.imshow('legend', resized_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Actually Its not symmetrical , we go ahead and divide by 2 / 3 the way we want it to resize. Also convert into 'int' bcoz it turns out to be in 'float'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"opencv.jpg\", 1)  \n",
    "\n",
    "resized_img = cv2.resize(img, (int(img.shape[1]/2), int(img.shape[0]/2)))   # basically it makes half the shape of img.\n",
    "\n",
    "cv2.imshow('legend', resized_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can also increase the size image , by multiplying with 2\n",
    "\n",
    "resized_img = cv2.resize(img, (int(img.shape[1]*2), int(img.shape[0]*2)))   # basically it makes half the shape of img."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Face Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Take a image - \n",
    "\n",
    "1.Create a 'cascade classifier' object, it will contain the features of the face (in xml file format). So that code determine where is the face.\n",
    "\n",
    "2.use OpenCV - read the image and features of file and convert image into Numpy array (or convert color image into grayscale).  \n",
    "3.detectMultiScale() : method to Search for the rows-columns values of the face numpy ndarray (face rectangle co-ordinates). scalefactor : decrease the shape value by 5%, until face is found. Smaller this value, greater is accuracy. \n",
    "\n",
    "4.Display the image with rectangular face box. (img, cordinates of img, RGB value of rectangle outline, width of rectangle)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### In order to do object recognition/detection with cascade files, you first need cascade files. For the extremely popular tasks, these already exist. Detecting things like faces, cars, smiles, eyes, and license plates. Go to the folder where cv2 (or openc cv) installed, \" opencv / data \" here find '' haarcascade files ''."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "[[283 255 469 469]]\n"
     ]
    }
   ],
   "source": [
    "face_cascade = cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\")\n",
    "\n",
    "img = cv2.imread(\"opencv.jpg\", 1) \n",
    "# img = cv2.imread('grayscale.jpg', 1)\n",
    "\n",
    "gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "faces = face_cascade.detectMultiScale(gray_img, scaleFactor=1.05, minNeighbors=5)\n",
    "\n",
    "print(type(faces))\n",
    "print(faces)\n",
    "\n",
    "# (x,y) - starting coordinates, (x+w, y+h) - cordinates upto 'w' width and 'h' height, (0,255,0) -rgb color box, width of box \n",
    "for (x,y,w,h) in faces:\n",
    "    img = cv2.rectangle(img, (x,y), (x+w, y+h), (0,255,0), 3)   \n",
    "    \n",
    "cv2.imshow('face detect', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Face and eye detect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_cascade = cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\")\n",
    "eye_cascade = cv2.CascadeClassifier(\"haarcascade_eye.xml\")\n",
    "\n",
    "img = cv2.imread(\"opencv.jpg\", 1) \n",
    "\n",
    "gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "faces = face_cascade.detectMultiScale(gray_img, scaleFactor=1.05, minNeighbors=5)\n",
    "\n",
    "for (x,y,w,h) in faces:\n",
    "    cv2.rectangle(img, (x,y), (x+w, y+h), (0,255,0), 3)       # detect face\n",
    "    \n",
    "    roi_gray = gray_img[y:y+h, x:x+w]       # it helps to get the face only\n",
    "    roi_color = img[y:y+h, x:x+w]\n",
    "    eyes = eye_cascade.detectMultiScale(roi_gray)   # and here detect eyes from 'roi_gray'\n",
    "    for (ex,ey,ew,eh) in eyes:\n",
    "        cv2.rectangle(roi_color,(ex,ey),(ex+ew,ey+eh),(0,255,111),2)\n",
    "        \n",
    "cv2.imshow('face & eye detect', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## -----------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to use OpenCV to capture video with computer webcam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use OpenCV for reading frames/ images one-by-one. video is nothing but multiple images/multiple frames which \n",
    "are displayed very quickly, so that it looks like a video.\n",
    "So we use loops to build a window where images appear really fast that you can see as a video.\n",
    "\n",
    "1.create a ' VideoCapture(0) ' object, It will trigger the camera. '0' this number tell the computer to use built-in camera.\n",
    "If want to use external camera then put here '1' and if using 2 cameras then put '2' inplcae of it.\n",
    "If we have video file, then we can give path to that video file.\n",
    "\n",
    "2.we need to import time module to use the camera for particular time (or to run the script).\n",
    "\n",
    "3.release() : this will release the camera in miliseconds.\n",
    "\n",
    "4.Now add a window that shows the video. \n",
    "\" check \" - Its boolean datatype, returns True, if python is able to read the VideoCapture Object.\n",
    "\" frame \" - It numpy array, it represents the first image that video captures.\n",
    "\n",
    "We need to create a frame object, which will read the images of the VideoCapture object.\n",
    "We will recessively show each frame of the video being captured.\n",
    "-> imshow() : to capture the 1st image / frame of the video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function destroyAllWindows>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2, time\n",
    "\n",
    "video = cv2.VideoCapture(0)\n",
    "\n",
    "check, frame = video.read()\n",
    "# print(check)  \n",
    "# print(frame)\n",
    "\n",
    "time.sleep(1)\n",
    "\n",
    "cv2.imshow('Capture', frame)     # show the frames / image of the video\n",
    "\n",
    "cv2.waitKey(0)\n",
    "\n",
    "video.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### till now we captured the 1st frame / image appeared in front of the camera"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In order to capture the video, we will use ' while loop ' and condition is such that, unless ' check ' is True, Python will display the frames, if not able to read then condition will be ' False '."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of frames captured : 171\n"
     ]
    }
   ],
   "source": [
    "import cv2, time\n",
    "\n",
    "video = cv2.VideoCapture(0)\n",
    "\n",
    "a = 1    # tells no. of frames, initially 1 \n",
    "\n",
    "while True:\n",
    "    a = a + 1       # here it will increase no .of frames by 1\n",
    "    \n",
    "    check, frame = video.read()\n",
    "#     print(frame)\n",
    "    \n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)  # convert each frame into gray scale image\n",
    "    cv2.imshow('Capture', gray)         # show image    \n",
    "    \n",
    "    key = cv2.waitKey(1)             # generate a new frame after every 1 miliseconds\n",
    "    \n",
    "    if key == ord('q'):\n",
    "        break                  # once press the 'q' loop breaks, window will be destroyed\n",
    "        \n",
    "\n",
    "print(f'No. of frames captured : {a}')   # print number of frames\n",
    "video.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### face and eye detect using webcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\")\n",
    "eye_cascade = cv2.CascadeClassifier(\"haarcascade_eye.xml\")\n",
    "\n",
    "# creating fucntion for detection of face and eyes \n",
    "def detect(gray, frame):\n",
    "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.05, minNeighbors=5)\n",
    "    for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(frame, (x,y), (x+w, y+h), (0,255,0), 3)       # detect face\n",
    "        \n",
    "        roi_gray = gray[y:y+h, x:x+w]       # it helps to get the face only\n",
    "        roi_color = frame[y:y+h, x:x+w]\n",
    "        eyes = eye_cascade.detectMultiScale(roi_gray, 1.1, 2)   # and here detect eyes from 'roi_gray'\n",
    "        for (ex,ey,ew,eh) in eyes:\n",
    "            cv2.rectangle(roi_color,(ex,ey),(ex+ew,ey+eh),(0,255,111),2)\n",
    "    return frame\n",
    "\n",
    "\n",
    "# Using webcam to detect\n",
    "video = cv2.VideoCapture(0)\n",
    "while True:\n",
    "    check, frame = video.read()\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    detection = detect(gray, frame)\n",
    "    cv2.imshow('face and eye detect webcam', detection)\n",
    "    \n",
    "    key = cv2.waitKey(1)\n",
    "    if key == ord('q'):\n",
    "        break\n",
    "\n",
    "video.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
